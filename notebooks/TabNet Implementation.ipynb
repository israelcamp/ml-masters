{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "inputs, targets = torch.tensor(iris.data[:]), torch.tensor(iris.target[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([150, 4]), torch.Size([150]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.shape, targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = len(targets.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = TensorDataset(inputs, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = DataLoader(ds, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(iter(dl))\n",
    "x = x.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_features = inputs.shape[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sparsemax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torch.autograd import Function\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch\n",
    "\n",
    "\"\"\"\n",
    "Other possible implementations:\n",
    "https://github.com/KrisKorrel/sparsemax-pytorch/blob/master/sparsemax.py\n",
    "https://github.com/msobroza/SparsemaxPytorch/blob/master/mnist/sparsemax.py\n",
    "https://github.com/vene/sparse-structured-attention/blob/master/pytorch/torchsparseattn/sparsemax.py\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# credits to Yandex https://github.com/Qwicen/node/blob/master/lib/nn_utils.py\n",
    "def _make_ix_like(input, dim=0):\n",
    "    d = input.size(dim)\n",
    "    rho = torch.arange(1, d + 1, device=input.device, dtype=input.dtype)\n",
    "    view = [1] * input.dim()\n",
    "    view[0] = -1\n",
    "    return rho.view(view).transpose(0, dim)\n",
    "\n",
    "\n",
    "class SparsemaxFunction(Function):\n",
    "    \"\"\"\n",
    "    An implementation of sparsemax (Martins & Astudillo, 2016). See\n",
    "    :cite:`DBLP:journals/corr/MartinsA16` for detailed description.\n",
    "    By Ben Peters and Vlad Niculae\n",
    "    \"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def forward(ctx, input, dim=-1):\n",
    "        \"\"\"sparsemax: normalizing sparse transform (a la softmax)\n",
    "        Parameters:\n",
    "            input (Tensor): any shape\n",
    "            dim: dimension along which to apply sparsemax\n",
    "        Returns:\n",
    "            output (Tensor): same shape as input\n",
    "        \"\"\"\n",
    "        ctx.dim = dim\n",
    "        max_val, _ = input.max(dim=dim, keepdim=True)\n",
    "        input -= max_val  # same numerical stability trick as for softmax\n",
    "        tau, supp_size = SparsemaxFunction._threshold_and_support(input, dim=dim)\n",
    "        output = torch.clamp(input - tau, min=0)\n",
    "        ctx.save_for_backward(supp_size, output)\n",
    "        return output\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        supp_size, output = ctx.saved_tensors\n",
    "        dim = ctx.dim\n",
    "        grad_input = grad_output.clone()\n",
    "        grad_input[output == 0] = 0\n",
    "\n",
    "        v_hat = grad_input.sum(dim=dim) / supp_size.to(output.dtype).squeeze()\n",
    "        v_hat = v_hat.unsqueeze(dim)\n",
    "        grad_input = torch.where(output != 0, grad_input - v_hat, grad_input)\n",
    "        return grad_input, None\n",
    "\n",
    "    @staticmethod\n",
    "    def _threshold_and_support(input, dim=-1):\n",
    "        \"\"\"Sparsemax building block: compute the threshold\n",
    "        Args:\n",
    "            input: any dimension\n",
    "            dim: dimension along which to apply the sparsemax\n",
    "        Returns:\n",
    "            the threshold value\n",
    "        \"\"\"\n",
    "\n",
    "        input_srt, _ = torch.sort(input, descending=True, dim=dim)\n",
    "        input_cumsum = input_srt.cumsum(dim) - 1\n",
    "        rhos = _make_ix_like(input, dim)\n",
    "        support = rhos * input_srt > input_cumsum\n",
    "\n",
    "        support_size = support.sum(dim=dim).unsqueeze(dim)\n",
    "        tau = input_cumsum.gather(dim, support_size - 1)\n",
    "        tau /= support_size.to(input.dtype)\n",
    "        return tau, support_size\n",
    "\n",
    "\n",
    "sparsemax = SparsemaxFunction.apply\n",
    "\n",
    "\n",
    "class Sparsemax(nn.Module):\n",
    "\n",
    "    def __init__(self, dim=-1):\n",
    "        self.dim = dim\n",
    "        super(Sparsemax, self).__init__()\n",
    "\n",
    "    def forward(self, input):\n",
    "        return sparsemax(input, self.dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The  Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GLU(nn.Module):\n",
    "\n",
    "    def __init__(self, units):\n",
    "        super().__init__()\n",
    "        self.units = units\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        return x[:, :self.units] * torch.sigmoid(x[:, self.units:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureTransformer(nn.Module):\n",
    "\n",
    "    def __init__(self, in_features, out_features, bn_momentum, previous_transformer=None):\n",
    "        super().__init__()\n",
    "        self.block1 = self.block(in_features, out_features, bn_momentum)\n",
    "        self.block2 = self.block(out_features, out_features, bn_momentum)\n",
    "        self.previous_transformer = previous_transformer\n",
    "\n",
    "    def block(self, in_features, out_features, bn_momentum):\n",
    "        return nn.Sequential(\n",
    "            nn.Linear(in_features, out_features * 2, bias=False),\n",
    "            nn.BatchNorm1d(out_features * 2, momentum=bn_momentum),\n",
    "            GLU(out_features)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.previous_transformer is not None:\n",
    "            x = self.previous_transformer(x)\n",
    "\n",
    "        o1 = self.block1(x)\n",
    "\n",
    "        if self.previous_transformer is not None:\n",
    "            o1 = (o1 + x) * math.sqrt(0.5)\n",
    "\n",
    "        o2 = self.block2(o1)\n",
    "        return (o2 + o1) * math.sqrt(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentiveTransformer(nn.Module):\n",
    "\n",
    "    def __init__(self, comp_size, n_features, relaxation_factor, epsilon):\n",
    "        super().__init__()\n",
    "        self.relaxation_factor = relaxation_factor\n",
    "        self.epsilon = epsilon\n",
    "\n",
    "        self.dense = nn.Linear(comp_size, n_features)\n",
    "        self.bn = nn.BatchNorm1d(n_features)\n",
    "        self.sparsemax = Sparsemax()\n",
    "\n",
    "    def forward(self, features_for_coef, complemantary_aggregated_mask_values):\n",
    "        mask_values = self.dense(features_for_coef)\n",
    "        mask_values = self.bn(mask_values)\n",
    "        mask_values =  mask_values * complemantary_aggregated_mask_values\n",
    "        mask_values = self.sparsemax(mask_values)\n",
    "\n",
    "        complemantary_aggregated_mask_values = complemantary_aggregated_mask_values * (\n",
    "            self.relaxation_factor - mask_values)\n",
    "        entropy = torch.sum(-mask_values *\n",
    "                            torch.log(mask_values + self.epsilon), dim=1)\n",
    "        entropy = entropy.mean()\n",
    "        return mask_values, complemantary_aggregated_mask_values, entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TabNet(nn.Module):\n",
    "\n",
    "    def __init__(self, n_features, hidden_size, output_dim, decision_steps=2,\n",
    "                 relaxation_factor=1, epsilon=1e-4, bn_momentum=0.7):\n",
    "        super().__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_dim = output_dim\n",
    "        self.n_features = n_features\n",
    "        self.decision_steps = decision_steps\n",
    "        self.bn_momentum = bn_momentum\n",
    "\n",
    "        self.bn = nn.BatchNorm1d(n_features, momentum=self.bn_momentum)\n",
    "\n",
    "        # feature transformer shared accross steps\n",
    "        self.shared_transformer = FeatureTransformer(n_features, hidden_size)\n",
    "\n",
    "        # step dependent feature transformer\n",
    "        self.step_transformers = nn.ModuleList([\n",
    "            FeatureTransformer(hidden_size, hidden_size, self.bn_momentum,\n",
    "                               self.shared_transformer)\n",
    "            for _ in range(decision_steps)\n",
    "        ])\n",
    "\n",
    "        self.attentive_transformers = nn.ModuleList([\n",
    "            AttentiveTransformer(\n",
    "                self.hidden_size-self.output_dim, self.n_features, relaxation_factor, epsilon)\n",
    "            for _ in range(decision_steps - 1)\n",
    "        ])\n",
    "\n",
    "    def forward(self, x, output_masks=False):\n",
    "        x = self.bn(x)  # applies batch norm on the input\n",
    "        batch_size = x.shape[0]\n",
    "        output_aggregated = torch.zeros(batch_size, self.output_dim).to(device)\n",
    "        mask_values = torch.zeros(batch_size, self.n_features).to(device)\n",
    "        aggregated_mask_values = torch.zeros(\n",
    "            batch_size, self.n_features).to(device)\n",
    "        complemantary_aggregated_mask_values = torch.ones(\n",
    "            batch_size, self.n_features).to(device)\n",
    "        total_entropy = 0\n",
    "\n",
    "        mask_values_per_step = []\n",
    "\n",
    "        masked_features = x\n",
    "\n",
    "        for i, step_transformer in enumerate(self.step_transformers):\n",
    "\n",
    "            o = step_transformer(masked_features)\n",
    "\n",
    "            if i > 0:\n",
    "                decision_out = F.relu(o[:, :self.output_dim])\n",
    "                output_aggregated = output_aggregated + decision_out\n",
    "\n",
    "                # for visualization\n",
    "                scale_agg = torch.sum(\n",
    "                    decision_out, dim=1, keepdim=True) / (self.decision_steps - 1)\n",
    "                aggregated_mask_values = aggregated_mask_values + mask_values * scale_agg\n",
    "\n",
    "            features_for_coef = o[:, self.output_dim:]\n",
    "\n",
    "            if i < self.decision_steps - 1:\n",
    "                attentive_transformer = self.attentive_transformers[i]\n",
    "                mask_values, complemantary_aggregated_mask_values, entropy = attentive_transformer(\n",
    "                    features_for_coef, complemantary_aggregated_mask_values)\n",
    "                total_entropy = total_entropy + \\\n",
    "                    entropy / (self.decision_steps - 1)\n",
    "\n",
    "                masked_features = mask_values * x\n",
    "\n",
    "                if output_masks:\n",
    "                    mask_values_per_step.append(mask_values.detach().cpu())\n",
    "\n",
    "        outputs = (output_aggregated, total_entropy)\n",
    "        if output_masks:\n",
    "            outputs = outputs + (aggregated_mask_values, mask_values_per_step)\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TabNetClassifier(nn.Module):\n",
    "    \n",
    "    def __init__(self, tabnet, output_dim, n_classes):\n",
    "        super().__init__()\n",
    "        self.tabnet = tabnet\n",
    "        self.classifier = nn.Linear(output_dim, n_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        output_aggregated, total_entropy = self.tabnet(x)\n",
    "        return self.classifier(output_aggregated)\n",
    "    \n",
    "    def to(self, device):\n",
    "        self.tabnet.to(device)\n",
    "        self.classifier.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_features = 16\n",
    "output_dim = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabnet = TabNet(in_features, out_features, output_dim, decision_steps=4)\n",
    "model = TabNetClassifier(tabnet, output_dim, n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    out = model(x.float().to(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridx = np.random.permutation(len(inputs))\n",
    "train_size = round(0.8 * len(inputs))\n",
    "train_idx = ridx[:train_size]\n",
    "valid_idx = ridx[train_size:]\n",
    "\n",
    "ds_train = TensorDataset(inputs[train_idx], targets[train_idx])\n",
    "ds_valid = TensorDataset(inputs[valid_idx], targets[valid_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_train = DataLoader(ds_train, batch_size=train_size, num_workers=4)\n",
    "dl_valid = DataLoader(ds_valid, batch_size=len(ds_valid), num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),  lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4800, device='cuda:0')\n",
      "tensor(0.4795, device='cuda:0')\n",
      "tensor(0.4805, device='cuda:0')\n",
      "tensor(0.4807, device='cuda:0')\n",
      "tensor(0.4799, device='cuda:0')\n",
      "tensor(0.4801, device='cuda:0')\n",
      "tensor(0.4802, device='cuda:0')\n",
      "tensor(0.4789, device='cuda:0')\n",
      "tensor(0.4763, device='cuda:0')\n",
      "tensor(0.4725, device='cuda:0')\n",
      "tensor(0.4691, device='cuda:0')\n",
      "tensor(0.4667, device='cuda:0')\n",
      "tensor(0.4629, device='cuda:0')\n",
      "tensor(0.4596, device='cuda:0')\n",
      "tensor(0.4598, device='cuda:0')\n",
      "tensor(0.4574, device='cuda:0')\n",
      "tensor(0.4491, device='cuda:0')\n",
      "tensor(0.4412, device='cuda:0')\n",
      "tensor(0.4420, device='cuda:0')\n",
      "tensor(0.4467, device='cuda:0')\n",
      "tensor(0.4306, device='cuda:0')\n",
      "tensor(0.4120, device='cuda:0')\n",
      "tensor(0.3958, device='cuda:0')\n",
      "tensor(0.3861, device='cuda:0')\n",
      "tensor(0.3804, device='cuda:0')\n",
      "tensor(0.3757, device='cuda:0')\n",
      "tensor(0.3718, device='cuda:0')\n",
      "tensor(0.3737, device='cuda:0')\n",
      "tensor(0.3756, device='cuda:0')\n",
      "tensor(0.3675, device='cuda:0')\n",
      "tensor(0.3708, device='cuda:0')\n",
      "tensor(0.3732, device='cuda:0')\n",
      "tensor(0.3738, device='cuda:0')\n",
      "tensor(0.3724, device='cuda:0')\n",
      "tensor(0.3674, device='cuda:0')\n",
      "tensor(0.3665, device='cuda:0')\n",
      "tensor(0.3670, device='cuda:0')\n",
      "tensor(0.3682, device='cuda:0')\n",
      "tensor(0.3698, device='cuda:0')\n",
      "tensor(0.3723, device='cuda:0')\n",
      "tensor(0.3739, device='cuda:0')\n",
      "tensor(0.3745, device='cuda:0')\n",
      "tensor(0.3756, device='cuda:0')\n",
      "tensor(0.3787, device='cuda:0')\n",
      "tensor(0.3823, device='cuda:0')\n",
      "tensor(0.3860, device='cuda:0')\n",
      "tensor(0.3902, device='cuda:0')\n",
      "tensor(0.3935, device='cuda:0')\n",
      "tensor(0.3949, device='cuda:0')\n",
      "tensor(0.3942, device='cuda:0')\n",
      "tensor(0.3931, device='cuda:0')\n",
      "tensor(0.3927, device='cuda:0')\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-576-07965c55e523>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtabnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdl_train\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/bertenv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    792\u001b[0m                 \u001b[0;31m# no valid `self.rcvd_idx` is found (i.e., didn't break)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 793\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown_workers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    794\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    795\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/bertenv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_shutdown_workers\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    904\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown_worker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworker_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    905\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 906\u001b[0;31m                     \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    907\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mq\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_queues\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    908\u001b[0m                     \u001b[0mq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcancel_join_thread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/bertenv/lib/python3.7/multiprocessing/process.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_pid\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetpid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'can only join a child process'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_popen\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'can only join a started process'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_popen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m             \u001b[0m_children\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiscard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/bertenv/lib/python3.7/multiprocessing/popen_fork.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m     46\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0;31m# This shouldn't block if wait() returned successfully.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWNOHANG\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0.0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/bertenv/lib/python3.7/multiprocessing/popen_fork.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, flag)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                 \u001b[0mpid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwaitpid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m                 \u001b[0;31m# Child process not yet created. See #1731717\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for _ in range(60):\n",
    "    model.train()\n",
    "    model.tabnet.train()\n",
    "    \n",
    "    for x, y in dl_train:\n",
    "        model.zero_grad()\n",
    "        \n",
    "        out = model(x.float().to(device))\n",
    "        loss = loss_fn(out, y.long().to(device))\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    model.eval()\n",
    "    model.tabnet.eval()\n",
    "    x, y = next(iter(dl_valid))\n",
    "    with torch.no_grad():\n",
    "        out = model(x.float().to(device))\n",
    "        loss_valid = loss_fn(out, y.long().to(device))\n",
    "    print(loss_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 577,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(out.argmax(-1).cpu() == y.long()).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_agg, _, agg_mask, mask_per_step = model.tabnet(x.float().to(device), True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(8.7213, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       " tensor(0., device='cuda:0', grad_fn=<MinBackward1>))"
      ]
     },
     "execution_count": 579,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_agg.max(), out_agg.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([120, 4]),\n",
       " tensor(4.0263, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       " tensor(0., device='cuda:0', grad_fn=<MinBackward1>))"
      ]
     },
     "execution_count": 580,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg_mask.shape, agg_mask.max(), agg_mask.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([120, 4])"
      ]
     },
     "execution_count": 581,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_per_step[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_mask = agg_mask.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_mask_norm = (agg_mask - agg_mask.min(0)) / (agg_mask.max(0) - agg_mask.min(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f33dbfa5650>"
      ]
     },
     "execution_count": 592,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(mask_per_step[1][1].unsqueeze(0), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3701, 0.3967, 2.2332, 0.0000],\n",
       "        [0.2653, 1.1035, 0.2962, 1.3350],\n",
       "        [1.2577, 0.9080, 0.0000, 0.8343],\n",
       "        [0.9581, 1.0243, 0.0000, 1.0175],\n",
       "        [0.0000, 0.8861, 1.0622, 1.0517],\n",
       "        [0.9209, 0.8975, 0.0000, 1.1817],\n",
       "        [0.0000, 0.5641, 1.1853, 1.2506],\n",
       "        [0.4527, 1.1838, 0.4944, 0.8691],\n",
       "        [1.0341, 0.9659, 0.0000, 1.0000],\n",
       "        [0.9362, 1.0638, 0.0000, 1.0000],\n",
       "        [0.3808, 0.8690, 0.9031, 0.8471],\n",
       "        [1.2842, 0.0000, 1.7087, 0.0071],\n",
       "        [0.3056, 0.7416, 0.4853, 1.4675],\n",
       "        [0.8606, 0.9423, 0.0000, 1.1971],\n",
       "        [0.9094, 0.9157, 0.0000, 1.1749],\n",
       "        [0.7653, 1.2177, 0.1185, 0.8985],\n",
       "        [0.3162, 0.0388, 1.2908, 1.3541],\n",
       "        [0.5687, 0.3320, 2.0993, 0.0000],\n",
       "        [0.3181, 0.0000, 1.9764, 0.7054],\n",
       "        [0.1541, 0.0000, 1.5158, 1.3301],\n",
       "        [0.7217, 1.1430, 0.0000, 1.1353],\n",
       "        [0.8598, 1.0226, 0.0000, 1.1176],\n",
       "        [0.2964, 0.0147, 1.9223, 0.7666],\n",
       "        [0.7447, 0.9163, 0.3153, 1.0237],\n",
       "        [0.6688, 1.1177, 0.3158, 0.8977],\n",
       "        [0.2664, 0.4752, 1.2583, 1.0000],\n",
       "        [0.4469, 0.6057, 1.9474, 0.0000],\n",
       "        [0.4634, 0.5976, 0.9038, 1.0353],\n",
       "        [0.4592, 0.1172, 2.0492, 0.3744],\n",
       "        [0.9858, 1.0730, 0.0000, 0.9413],\n",
       "        [0.6676, 1.0284, 0.1682, 1.1357],\n",
       "        [0.9346, 0.2216, 1.8439, 0.0000],\n",
       "        [0.1202, 1.0000, 0.8208, 1.0590],\n",
       "        [0.9866, 1.0766, 0.0000, 0.9368],\n",
       "        [1.1330, 0.2857, 0.0000, 1.5813],\n",
       "        [0.9270, 1.0730, 0.0000, 1.0000],\n",
       "        [1.0405, 1.0498, 0.0000, 0.9097],\n",
       "        [1.1405, 0.9595, 0.0000, 0.9000],\n",
       "        [0.7047, 1.1264, 0.1565, 1.0123],\n",
       "        [0.4938, 0.5101, 1.9961, 0.0000],\n",
       "        [0.8367, 0.9900, 0.0000, 1.1734],\n",
       "        [0.8017, 1.0050, 0.0000, 1.1934],\n",
       "        [1.1470, 0.6216, 0.0000, 1.2314],\n",
       "        [0.6825, 0.5563, 1.7612, 0.0000],\n",
       "        [0.5587, 0.5101, 1.9312, 0.0000],\n",
       "        [0.0000, 0.0000, 1.5000, 1.5000],\n",
       "        [0.0000, 1.0000, 1.0000, 1.0000],\n",
       "        [0.4447, 1.0987, 0.3601, 1.0966],\n",
       "        [0.7111, 1.0742, 0.1178, 1.0968],\n",
       "        [1.1029, 1.0409, 0.0000, 0.8562],\n",
       "        [0.5285, 0.3337, 2.1378, 0.0000],\n",
       "        [1.2167, 0.8818, 0.0000, 0.9015],\n",
       "        [1.0413, 1.0587, 0.0000, 0.8999],\n",
       "        [0.7011, 0.2096, 2.0780, 0.0112],\n",
       "        [1.0943, 1.0163, 0.0000, 0.8893],\n",
       "        [1.0070, 0.1302, 0.4370, 1.4258],\n",
       "        [1.0413, 1.1176, 0.0000, 0.8411],\n",
       "        [0.8300, 1.1857, 0.0000, 0.9843],\n",
       "        [1.0588, 1.0588, 0.0000, 0.8824],\n",
       "        [0.6125, 1.1186, 0.1715, 1.0974],\n",
       "        [0.2510, 0.0027, 1.8861, 0.8602],\n",
       "        [0.3296, 0.9470, 0.3121, 1.4113],\n",
       "        [0.8605, 0.9491, 0.3103, 0.8801],\n",
       "        [1.0061, 0.8088, 0.0859, 1.0992],\n",
       "        [0.6589, 1.1364, 0.1195, 1.0852],\n",
       "        [0.6895, 1.1721, 0.0557, 1.0826],\n",
       "        [0.7516, 1.0650, 0.3360, 0.8474],\n",
       "        [0.7080, 0.7334, 1.5585, 0.0000],\n",
       "        [0.3396, 0.0000, 1.4624, 1.1981],\n",
       "        [1.0260, 1.0847, 0.0000, 0.8893],\n",
       "        [0.9534, 0.8634, 0.0000, 1.1832],\n",
       "        [0.7729, 1.1546, 0.0432, 1.0293],\n",
       "        [0.9233, 0.9277, 0.0000, 1.1490],\n",
       "        [0.0000, 0.5438, 1.2205, 1.2357],\n",
       "        [0.8589, 0.9602, 0.0000, 1.1809],\n",
       "        [0.0000, 0.1018, 1.4491, 1.4491],\n",
       "        [0.0000, 0.2692, 1.1640, 1.5668],\n",
       "        [0.0905, 1.3412, 0.1382, 1.4301],\n",
       "        [1.0673, 0.0236, 1.8891, 0.0201],\n",
       "        [1.0056, 1.0597, 0.0000, 0.9347],\n",
       "        [0.2519, 0.0000, 1.4721, 1.2760],\n",
       "        [0.6644, 0.5571, 1.7785, 0.0000],\n",
       "        [0.8531, 0.9507, 0.0000, 1.1962],\n",
       "        [0.5585, 0.9393, 0.2081, 1.2940],\n",
       "        [1.2766, 0.6571, 0.0000, 1.0663],\n",
       "        [0.4738, 0.5571, 1.9691, 0.0000],\n",
       "        [0.9921, 1.0067, 0.0000, 1.0011],\n",
       "        [0.3926, 1.0207, 0.7703, 0.8164],\n",
       "        [1.0371, 1.1022, 0.0000, 0.8607],\n",
       "        [1.2828, 0.6383, 0.0000, 1.0789],\n",
       "        [0.4568, 0.0000, 1.9960, 0.5472],\n",
       "        [0.5186, 0.3998, 2.0816, 0.0000],\n",
       "        [1.1107, 0.0000, 0.0000, 1.8893],\n",
       "        [0.3312, 0.6962, 1.7593, 0.2132],\n",
       "        [1.0357, 1.0779, 0.0000, 0.8864],\n",
       "        [0.5628, 1.0585, 0.6835, 0.6952],\n",
       "        [0.3746, 0.4677, 2.1577, 0.0000],\n",
       "        [1.0577, 1.0047, 0.0000, 0.9376],\n",
       "        [1.1272, 0.0000, 1.4475, 0.4254],\n",
       "        [0.5655, 0.6529, 1.7816, 0.0000],\n",
       "        [1.3189, 0.3410, 0.0000, 1.3401],\n",
       "        [1.0131, 1.0366, 0.0000, 0.9503],\n",
       "        [1.3093, 0.0000, 1.3950, 0.2956],\n",
       "        [1.0472, 0.8261, 0.7423, 0.3844],\n",
       "        [0.0000, 0.7300, 1.1577, 1.1123],\n",
       "        [0.7854, 0.3760, 1.8386, 0.0000],\n",
       "        [0.5221, 1.0000, 1.0352, 0.4427],\n",
       "        [0.0000, 0.5094, 1.2545, 1.2361],\n",
       "        [1.0266, 1.0806, 0.0000, 0.8928],\n",
       "        [0.8208, 1.0002, 0.0000, 1.1790],\n",
       "        [1.0266, 1.0806, 0.0000, 0.8928],\n",
       "        [0.7170, 0.5342, 0.9208, 0.8280],\n",
       "        [1.1667, 0.9377, 0.0000, 0.8955],\n",
       "        [0.5215, 1.0196, 0.2848, 1.1742],\n",
       "        [0.4424, 0.0411, 1.4907, 1.0258],\n",
       "        [1.0455, 1.1094, 0.0000, 0.8450],\n",
       "        [0.8987, 1.1153, 0.0000, 0.9860],\n",
       "        [0.4861, 0.9050, 0.5322, 1.0768],\n",
       "        [0.5423, 0.0000, 1.3897, 1.0680],\n",
       "        [0.2193, 0.7951, 0.3385, 1.6471]])"
      ]
     },
     "execution_count": 595,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(mask_per_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f34307eca10>"
      ]
     },
     "execution_count": 502,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(agg_mask_norm, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit ('bertenv': conda)",
   "language": "python",
   "name": "python37464bitbertenvcondabe30b9b65ccd476ab0afdaa5ea99afd8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
