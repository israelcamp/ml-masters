{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, auc, roc_auc_score\n",
    "from sklearn.metrics import precision_recall_curve, average_precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlpack.utils import to_device, to_fp16\n",
    "from mlpack.trainer import TrainArgs, BaseTrainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_id = pd.read_csv('../datasets/ENEL/log_norm_clean_data_train.csv', usecols=[0], sep=',')\n",
    "valid_id = pd.read_csv('../datasets/ENEL/log_norm_clean_data_valid.csv', usecols=[0], sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2014-01-01 00:00:00</th>\n",
       "      <th>2014-01-02 00:00:00</th>\n",
       "      <th>2014-01-03 00:00:00</th>\n",
       "      <th>2014-01-04 00:00:00</th>\n",
       "      <th>2014-01-05 00:00:00</th>\n",
       "      <th>2014-01-06 00:00:00</th>\n",
       "      <th>2014-01-07 00:00:00</th>\n",
       "      <th>2014-01-08 00:00:00</th>\n",
       "      <th>2014-01-09 00:00:00</th>\n",
       "      <th>2014-01-10 00:00:00</th>\n",
       "      <th>...</th>\n",
       "      <th>2016-10-23 00:00:00</th>\n",
       "      <th>2016-10-24 00:00:00</th>\n",
       "      <th>2016-10-25 00:00:00</th>\n",
       "      <th>2016-10-26 00:00:00</th>\n",
       "      <th>2016-10-27 00:00:00</th>\n",
       "      <th>2016-10-28 00:00:00</th>\n",
       "      <th>2016-10-29 00:00:00</th>\n",
       "      <th>2016-10-30 00:00:00</th>\n",
       "      <th>2016-10-31 00:00:00</th>\n",
       "      <th>flag</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CONS_NO</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0387DD8A07E07FDA6271170F86AD9151</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.305338</td>\n",
       "      <td>0.306095</td>\n",
       "      <td>0.360579</td>\n",
       "      <td>0.207343</td>\n",
       "      <td>0.331067</td>\n",
       "      <td>0.351877</td>\n",
       "      <td>0.285285</td>\n",
       "      <td>0.346580</td>\n",
       "      <td>0.255016</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>01D6177B5D4FFE0CABA9EF17DAFC2B84</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4B75AC4F2D8434CFF62DB64D0BB43103</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.963074</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>B32AC8CC6D5D805AC053557AB05F5343</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.497605</td>\n",
       "      <td>0.568034</td>\n",
       "      <td>0.490694</td>\n",
       "      <td>0.644715</td>\n",
       "      <td>0.684207</td>\n",
       "      <td>0.590742</td>\n",
       "      <td>0.633854</td>\n",
       "      <td>0.475885</td>\n",
       "      <td>0.385710</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>EDFC78B07BA2908B3395C4EB2304665E</td>\n",
       "      <td>0.106331</td>\n",
       "      <td>0.248451</td>\n",
       "      <td>0.318474</td>\n",
       "      <td>0.128116</td>\n",
       "      <td>0.143158</td>\n",
       "      <td>0.233409</td>\n",
       "      <td>0.201251</td>\n",
       "      <td>0.146789</td>\n",
       "      <td>0.139008</td>\n",
       "      <td>0.133303</td>\n",
       "      <td>...</td>\n",
       "      <td>0.486010</td>\n",
       "      <td>0.395240</td>\n",
       "      <td>0.272830</td>\n",
       "      <td>0.272311</td>\n",
       "      <td>0.304988</td>\n",
       "      <td>0.345965</td>\n",
       "      <td>0.520762</td>\n",
       "      <td>0.467337</td>\n",
       "      <td>0.408207</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 1035 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  2014-01-01 00:00:00  2014-01-02 00:00:00  \\\n",
       "CONS_NO                                                                      \n",
       "0387DD8A07E07FDA6271170F86AD9151             0.000000             0.000000   \n",
       "01D6177B5D4FFE0CABA9EF17DAFC2B84             0.000000             0.000000   \n",
       "4B75AC4F2D8434CFF62DB64D0BB43103             0.000000             0.000000   \n",
       "B32AC8CC6D5D805AC053557AB05F5343             0.000000             0.000000   \n",
       "EDFC78B07BA2908B3395C4EB2304665E             0.106331             0.248451   \n",
       "\n",
       "                                  2014-01-03 00:00:00  2014-01-04 00:00:00  \\\n",
       "CONS_NO                                                                      \n",
       "0387DD8A07E07FDA6271170F86AD9151             0.000000             0.000000   \n",
       "01D6177B5D4FFE0CABA9EF17DAFC2B84             0.000000             0.000000   \n",
       "4B75AC4F2D8434CFF62DB64D0BB43103             0.000000             0.000000   \n",
       "B32AC8CC6D5D805AC053557AB05F5343             0.000000             0.000000   \n",
       "EDFC78B07BA2908B3395C4EB2304665E             0.318474             0.128116   \n",
       "\n",
       "                                  2014-01-05 00:00:00  2014-01-06 00:00:00  \\\n",
       "CONS_NO                                                                      \n",
       "0387DD8A07E07FDA6271170F86AD9151             0.000000             0.000000   \n",
       "01D6177B5D4FFE0CABA9EF17DAFC2B84             0.000000             0.000000   \n",
       "4B75AC4F2D8434CFF62DB64D0BB43103             0.000000             0.000000   \n",
       "B32AC8CC6D5D805AC053557AB05F5343             0.000000             0.000000   \n",
       "EDFC78B07BA2908B3395C4EB2304665E             0.143158             0.233409   \n",
       "\n",
       "                                  2014-01-07 00:00:00  2014-01-08 00:00:00  \\\n",
       "CONS_NO                                                                      \n",
       "0387DD8A07E07FDA6271170F86AD9151             0.000000             0.000000   \n",
       "01D6177B5D4FFE0CABA9EF17DAFC2B84             0.000000             0.000000   \n",
       "4B75AC4F2D8434CFF62DB64D0BB43103             0.000000             0.000000   \n",
       "B32AC8CC6D5D805AC053557AB05F5343             0.000000             0.000000   \n",
       "EDFC78B07BA2908B3395C4EB2304665E             0.201251             0.146789   \n",
       "\n",
       "                                  2014-01-09 00:00:00  2014-01-10 00:00:00  \\\n",
       "CONS_NO                                                                      \n",
       "0387DD8A07E07FDA6271170F86AD9151             0.000000             0.000000   \n",
       "01D6177B5D4FFE0CABA9EF17DAFC2B84             0.000000             0.000000   \n",
       "4B75AC4F2D8434CFF62DB64D0BB43103             0.000000             0.000000   \n",
       "B32AC8CC6D5D805AC053557AB05F5343             0.000000             0.000000   \n",
       "EDFC78B07BA2908B3395C4EB2304665E             0.139008             0.133303   \n",
       "\n",
       "                                  ...  2016-10-23 00:00:00  \\\n",
       "CONS_NO                           ...                        \n",
       "0387DD8A07E07FDA6271170F86AD9151  ...             0.305338   \n",
       "01D6177B5D4FFE0CABA9EF17DAFC2B84  ...             0.000000   \n",
       "4B75AC4F2D8434CFF62DB64D0BB43103  ...             1.000000   \n",
       "B32AC8CC6D5D805AC053557AB05F5343  ...             0.497605   \n",
       "EDFC78B07BA2908B3395C4EB2304665E  ...             0.486010   \n",
       "\n",
       "                                  2016-10-24 00:00:00  2016-10-25 00:00:00  \\\n",
       "CONS_NO                                                                      \n",
       "0387DD8A07E07FDA6271170F86AD9151             0.306095             0.360579   \n",
       "01D6177B5D4FFE0CABA9EF17DAFC2B84             0.000000             0.000000   \n",
       "4B75AC4F2D8434CFF62DB64D0BB43103             1.000000             1.000000   \n",
       "B32AC8CC6D5D805AC053557AB05F5343             0.568034             0.490694   \n",
       "EDFC78B07BA2908B3395C4EB2304665E             0.395240             0.272830   \n",
       "\n",
       "                                  2016-10-26 00:00:00  2016-10-27 00:00:00  \\\n",
       "CONS_NO                                                                      \n",
       "0387DD8A07E07FDA6271170F86AD9151             0.207343             0.331067   \n",
       "01D6177B5D4FFE0CABA9EF17DAFC2B84             0.000000             0.000000   \n",
       "4B75AC4F2D8434CFF62DB64D0BB43103             1.000000             1.000000   \n",
       "B32AC8CC6D5D805AC053557AB05F5343             0.644715             0.684207   \n",
       "EDFC78B07BA2908B3395C4EB2304665E             0.272311             0.304988   \n",
       "\n",
       "                                  2016-10-28 00:00:00  2016-10-29 00:00:00  \\\n",
       "CONS_NO                                                                      \n",
       "0387DD8A07E07FDA6271170F86AD9151             0.351877             0.285285   \n",
       "01D6177B5D4FFE0CABA9EF17DAFC2B84             0.000000             0.000000   \n",
       "4B75AC4F2D8434CFF62DB64D0BB43103             1.000000             1.000000   \n",
       "B32AC8CC6D5D805AC053557AB05F5343             0.590742             0.633854   \n",
       "EDFC78B07BA2908B3395C4EB2304665E             0.345965             0.520762   \n",
       "\n",
       "                                  2016-10-30 00:00:00  2016-10-31 00:00:00  \\\n",
       "CONS_NO                                                                      \n",
       "0387DD8A07E07FDA6271170F86AD9151             0.346580             0.255016   \n",
       "01D6177B5D4FFE0CABA9EF17DAFC2B84             0.000000             0.000000   \n",
       "4B75AC4F2D8434CFF62DB64D0BB43103             1.000000             0.963074   \n",
       "B32AC8CC6D5D805AC053557AB05F5343             0.475885             0.385710   \n",
       "EDFC78B07BA2908B3395C4EB2304665E             0.467337             0.408207   \n",
       "\n",
       "                                  flag  \n",
       "CONS_NO                                 \n",
       "0387DD8A07E07FDA6271170F86AD9151     1  \n",
       "01D6177B5D4FFE0CABA9EF17DAFC2B84     1  \n",
       "4B75AC4F2D8434CFF62DB64D0BB43103     1  \n",
       "B32AC8CC6D5D805AC053557AB05F5343     1  \n",
       "EDFC78B07BA2908B3395C4EB2304665E     1  \n",
       "\n",
       "[5 rows x 1035 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../datasets/ENEL/dataset.csv', sep='\\t', index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df.loc[train_id.values[:,0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valid = df.loc[valid_id.values[:,0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = df_train.values[:,:-1]\n",
    "y_train = df_train.values[:,-1]\n",
    "\n",
    "x_valid = df_valid.values[:,:-1]\n",
    "y_valid = df_valid.values[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.concatenate(([2*[0] for _ in range(len(x_train))], x_train), axis=1)\n",
    "x_valid = np.concatenate(([2*[0] for _ in range(len(x_valid))], x_valid), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((21489, 1036), (5373, 1036))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, x_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(len(x_train), -1, 7)\n",
    "x_train = np.expand_dims(x_train, 1)\n",
    "\n",
    "x_valid = x_valid.reshape(len(x_valid), -1, 7)\n",
    "x_valid = np.expand_dims(x_valid, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((21489, 1, 148, 7), (5373, 1, 148, 7))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, x_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_ones = x_train[y_train == 1]\n",
    "y_train_ones = y_train[y_train == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.vstack((x_train, x_train_ones, x_train_ones, x_train_ones))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.concatenate((y_train, y_train_ones, y_train_ones, y_train_ones))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1616, 1, 148, 7)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_ones.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((26337,), (26337, 1, 148, 7))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape, x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ENELDataset(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        self.x, self.y = x, y\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        x, y = self.x[idx], self.y[idx]\n",
    "#         if y == 0:\n",
    "#             if random.random() < 0.1:\n",
    "#                 i = random.randint(0, len(x_train_ones)-1)\n",
    "#                 x, y = x_train_ones[i], y_train_ones[i]\n",
    "        \n",
    "        return x.astype(np.float32), y.astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = ENELDataset(x_train, y_train)\n",
    "ds_valid = ENELDataset(x_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_train = DataLoader(ds_train, batch_size=32, shuffle=True, pin_memory=True, num_workers=4)\n",
    "dl_valid = DataLoader(ds_valid, batch_size=32, shuffle=False, pin_memory=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "# device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttention(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_size, out_size):\n",
    "        super().__init__()\n",
    "        self.query = nn.Linear(in_size, out_size)\n",
    "        self.key = nn.Linear(in_size, out_size)\n",
    "        self.value = nn.Linear(in_size, out_size)\n",
    "        \n",
    "        self.d = out_size**(0.5)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        q = self.query(x)\n",
    "        k = self.key(x)\n",
    "        v = self.value(x)\n",
    "        z = torch.softmax((q @ k.permute(0, 1, 3, 2))/self.d, dim=-1) @ v\n",
    "        return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvModel(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        dropout = 0.1\n",
    "\n",
    "        self.net = nn.Sequential(            \n",
    "            self.block(7,64, 1, 90, dropout),\n",
    "            self.block(64, 64, 90, 90, dropout),\n",
    "            self.block(64, 64, 90, 90, dropout),\n",
    "            nn.MaxPool2d(3),\n",
    "        )\n",
    "        self.classifier = nn.Linear(90 * 49 * 21, 2)\n",
    "\n",
    "    def block(self, in_features, out_features, in_channels, out_channels, dropout):\n",
    "        return nn.Sequential(\n",
    "            SelfAttention(in_features, out_features),  # n x in_channels x m x out_features\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),  # n x out_channels x m x out_features\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        o = self.net(x)\n",
    "        o = o.view(x.shape[0], -1)\n",
    "        o = self.classifier(o) \n",
    "        return o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConvModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvModel(\n",
       "  (net): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): SelfAttention(\n",
       "        (query): Linear(in_features=7, out_features=64, bias=True)\n",
       "        (key): Linear(in_features=7, out_features=64, bias=True)\n",
       "        (value): Linear(in_features=7, out_features=64, bias=True)\n",
       "      )\n",
       "      (1): Conv2d(1, 90, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (2): ReLU()\n",
       "      (3): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): SelfAttention(\n",
       "        (query): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (key): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (value): Linear(in_features=64, out_features=64, bias=True)\n",
       "      )\n",
       "      (1): Conv2d(90, 90, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (2): ReLU()\n",
       "      (3): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): SelfAttention(\n",
       "        (query): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (key): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (value): Linear(in_features=64, out_features=64, bias=True)\n",
       "      )\n",
       "      (1): Conv2d(90, 90, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (2): ReLU()\n",
       "      (3): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (classifier): Linear(in_features=92610, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(iter(dl_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 2])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    o = model(x.to(device))\n",
    "o.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def precision_at_k(y_true,class_probs,k,threshold=0.5,class_of_interest=1,isSorted=False):\n",
    "\n",
    "    if (not isSorted):\n",
    "\n",
    "        # Selecting the probs on the class of interest (coi)\n",
    "        coi_probs = class_probs[:,class_of_interest]\n",
    "\n",
    "        # print('Selecionando as probs da classe de interesse:',class_of_interest)\n",
    "        # print(coi_probs)\n",
    "\n",
    "        # print('Ordem de entrada dos targets')\n",
    "        # print(y_true)\n",
    "\n",
    "        # Sorting the coi probs and selecting the top k\n",
    "        # print('Ordenando as probs e os targets correspondentes:')\n",
    "        sorted_coi_probs = np.sort(coi_probs)[::-1]\n",
    "        sorted_y = y_true[np.argsort(coi_probs)[::-1]]\n",
    "        \n",
    "        # Calculating the precision for \n",
    "        # print(sorted_coi_probs)\n",
    "        # print(sorted_y)\n",
    "\n",
    "    else:\n",
    "        # Code otimization so the algorithm doesn't have to sort the data twice\n",
    "        sorted_coi_probs = class_probs\n",
    "        sorted_y = y_true\n",
    "\n",
    "\n",
    "    # Selecting the top k probs and their respective labels\n",
    "    sorted_coi_probs = sorted_coi_probs[:k]\n",
    "    sorted_y = sorted_y[:k]\n",
    "\n",
    "    # print('Selecionando as top',k,'probs')\n",
    "    # print(sorted_coi_probs)\n",
    "    # print(sorted_y)\n",
    "\n",
    "    # Atributing class based on the threshold\n",
    "    sorted_predicted_classes = np.where(sorted_coi_probs>threshold,\n",
    "                                        float(class_of_interest),\n",
    "                                        0.0)\n",
    "\n",
    "    # print('Atribuindo a classe baseada no threshold de ',threshold)\n",
    "    print(sorted_predicted_classes)\n",
    "\n",
    "    # print('PrecisÃ£o em K:')\n",
    "\n",
    "    # print(k)\n",
    "\n",
    "    precisionK = np.sum(sorted_predicted_classes == sorted_y)/k  \n",
    "\n",
    "    return precisionK\n",
    "\n",
    "def map_at_N(y_true,class_probs,N,thrs=0.5,class_of_interest=1):\n",
    "\n",
    "    # Calls the precision at k function with the values already sorted and calculates the average precision\n",
    "    # weighted by the number of positive classes inside the sample\n",
    "\n",
    "    # Declaring the list to hold the precisions\n",
    "    pks = []\n",
    "\n",
    "    # Selecting the probs on the class of interest (coi)\n",
    "    coi_probs = class_probs[:,class_of_interest]\n",
    "\n",
    "    # Sorting the class of interest and its respective label\n",
    "    sorted_coi_probs = np.sort(coi_probs)[::-1]\n",
    "    sorted_y = y_true[np.argsort(coi_probs)[::-1]]\n",
    "\n",
    "    # Selecting the top N scores \n",
    "    sorted_coi_probs = sorted_coi_probs[:N]\n",
    "    sorted_y = sorted_y[:N]\n",
    "\n",
    "\n",
    "    ## TESTANDO APENAS ##\n",
    "    sorted_y[-1] = 1 \n",
    "\n",
    "    # Identifying the positions of the class of interest inside the top N\n",
    "    top_coi_indexes = np.argwhere(sorted_y>0)\n",
    "\n",
    "    for value in top_coi_indexes:\n",
    "        \n",
    "        # Adjusting the index\n",
    "        limite = value[0] + 1\n",
    "        \n",
    "        pks.append(\n",
    "                    precision_at_k(sorted_y[:limite],\n",
    "                    sorted_coi_probs[:limite],\n",
    "                    limite,threshold=thrs,isSorted=True)\n",
    "                    )\n",
    "\n",
    "    pks = np.array(pks)\n",
    "    \n",
    "    # print(pks)\n",
    "    # print(sorted_coi_probs)\n",
    "    # print(sorted_y)\n",
    "    return pks.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyTrainer(BaseTrainer):\n",
    "    \n",
    "    @staticmethod\n",
    "    def dataloader_generator(dataloader):\n",
    "        for x, y in dataloader:\n",
    "#             x = x.unsqueeze(-1)\n",
    "            x, y = to_device(x, y, device=device)\n",
    "            yield {\n",
    "                'inputs': {\n",
    "                    'x': x\n",
    "                },\n",
    "                'targets': {\n",
    "                    'y': y\n",
    "                }\n",
    "            }\n",
    "        \n",
    "    @staticmethod\n",
    "    def loss_from_model(model_output, targets, loss_fn=None):\n",
    "        y = targets['y']\n",
    "        return loss_fn(model_output, y)\n",
    "    \n",
    "    def evaluate_fn(self, model, dataloader, loss_fn):\n",
    "        model.eval()\n",
    "        losses = []\n",
    "        preds = []\n",
    "        trues = []\n",
    "        probs = []\n",
    "        dl_gen = self.dataloader_generator(dataloader)\n",
    "        for batch in self.tqdm(dl_gen, leave=False, desc='Eval...', total=len(dataloader)):\n",
    "            inputs = batch['inputs']\n",
    "            targets = batch['targets']\n",
    "\n",
    "            with torch.no_grad():\n",
    "                o = model(**inputs)\n",
    "\n",
    "            loss = self.loss_from_model(o, targets, loss_fn)\n",
    "\n",
    "            y = targets['y']\n",
    "            \n",
    "            probs += o.detach().cpu().numpy().tolist()\n",
    "            preds += o.argmax(1).detach().cpu().numpy().tolist()\n",
    "            trues += y.detach().cpu().numpy().tolist()\n",
    "            losses.append(loss.item())\n",
    "\n",
    "        acc = accuracy_score(trues, preds)\n",
    "        f1 = f1_score(trues, preds)\n",
    "        conf = confusion_matrix(trues, preds)\n",
    "#         map100 = map_at_N(np.array(trues), np.array(probs), 100)\n",
    "\n",
    "        both = sorted([\n",
    "            (x, y) for x, y in zip(preds, trues)\n",
    "        ], key=lambda x:x[0], reverse=True)\n",
    "\n",
    "        p = [x for x,_ in both]\n",
    "        t = [x for _,x in both]\n",
    "\n",
    "        print('--- Validation ---')\n",
    "        print(f'F1 = {f1}\\t Acc = {acc}')\n",
    "        print(f'AUC = {auc(p, t)}')\n",
    "#         print(f'MAP@100 = {map100}')\n",
    "        print(conf)\n",
    "        return np.array(losses).mean(), f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss(torch.tensor([0.5, 1.]).to(device))\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = TrainArgs(40, 'enel_selfatt_conv.ckp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = MyTrainer(grad_steps=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# trainer.evaluate_fn(model, dl_valid, loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e7642b6068f4c7eb6b2bf5b446e0c39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Training...', max=40, style=ProgressStyle(description_width='â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39d8bdde443b4449a5eb73c6ddb19041",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=824), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 242.00 MiB (GPU 0; 3.95 GiB total capacity; 2.59 GiB already allocated; 123.19 MiB free; 274.95 MiB cached)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-f8160df15416>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdl_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdl_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/Mestrado/MLMaster/mlpack/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, args, model, dl_train, dl_valid, optimizer, loss_fn, scheduler)\u001b[0m\n\u001b[1;32m    113\u001b[0m                         amp.master_params(optimizer), self.max_grad_norm)\n\u001b[1;32m    114\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m                     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m                     torch.nn.utils.clip_grad_norm_(\n\u001b[1;32m    117\u001b[0m                         model.parameters(), self.max_grad_norm)\n",
      "\u001b[0;32m~/miniconda3/envs/bertenv/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    116\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \"\"\"\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/bertenv/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     91\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     92\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 242.00 MiB (GPU 0; 3.95 GiB total capacity; 2.59 GiB already allocated; 123.19 MiB free; 274.95 MiB cached)"
     ]
    }
   ],
   "source": [
    "trainer.train(args, model, dl_train, dl_valid, optimizer, loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:bertenv]",
   "language": "python",
   "name": "conda-env-bertenv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
