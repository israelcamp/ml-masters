{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook as tqdm\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from transformers.tokenization_bert import BertTokenizer\n",
    "from transformers.modeling_bert import BertForTokenClassification, BertConfig, BertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlpack.datasets.conll2003 import get_conll2003, get_conll2003_features, convert_examples_to_features_masked\n",
    "from mlpack.datasets.conll2003 import CoNLL2003Dataset, InputFeatures\n",
    "from mlpack.bert.ner.model import BertForMaskedNERClassification, BertForNERClassification\n",
    "from mlpack.bert.ner.train import train\n",
    "from mlpack.bert.ner.utils import to_fp16, to_device\n",
    "from mlpack.utils import save_pickle, read_pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer('../bert-base-cased/vocab.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_words_set_from_examples(examples):\n",
    "    words = sum([\n",
    "        ex.text_a.split(' ') for ex in examples\n",
    "    ], [])\n",
    "    return list(set(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples, labels = get_conll2003('../datasets/CoNLL2003/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_words = get_all_words_set_from_examples(examples['train'])\n",
    "valid_words = get_all_words_set_from_examples(examples['valid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9966, 6706)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(valid_words), len([w for w in valid_words if w in train_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: '[PAD]',\n",
       " 1: 'O',\n",
       " 2: 'B-MISC',\n",
       " 3: 'I-MISC',\n",
       " 4: 'B-PER',\n",
       " 5: 'I-PER',\n",
       " 6: 'B-ORG',\n",
       " 7: 'I-ORG',\n",
       " 8: 'B-LOC',\n",
       " 9: 'I-LOC',\n",
       " 10: '[CLS]',\n",
       " 11: '[SEP]',\n",
       " 12: 'X'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_map = {i:l for i, l in enumerate(labels, 0)}\n",
    "label_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_attrs = ['input_ids', 'input_mask', 'segment_ids', 'label_id', 'valid_ids', 'label_mask', 'masked_word']\n",
    "def features_to_pickle(features, filename):\n",
    "    feats = [\n",
    "        { attr: feat.__getattribute__(attr) for attr in feat_attrs }\n",
    "        for feat in features\n",
    "    ]\n",
    "    save_pickle(feats, filename)\n",
    "    \n",
    "def pickle_to_features(filename):\n",
    "    feats = read_pickle(filename)\n",
    "    return [\n",
    "        InputFeatures(**attrs) for attrs in feats\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_pickle = 'train_feats.pickle'\n",
    "valid_pickle = 'valid_feats.pickle'\n",
    "# if os.path.exists(train_pickle):\n",
    "#     features_train = pickle_to_features(train_pickle)\n",
    "# else:\n",
    "#     features_train = convert_examples_to_features_masked(examples['train'], labels, 128, tokenizer)\n",
    "#     features_to_pickle(features_train, train_pickle)\n",
    "    \n",
    "if os.path.exists(valid_pickle):\n",
    "    features_valid = pickle_to_features(valid_pickle)\n",
    "else:\n",
    "    features_valid = convert_examples_to_features_masked(examples['valid'], labels, 128, tokenizer)\n",
    "    features_to_pickle(features_valid, valid_pickle)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_normal_features = convert_examples_to_features_masked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# valid features with masked word on train\n",
    "onmask_feats = [\n",
    "    feat for feat in features_valid if feat.masked_word in train_words\n",
    "]\n",
    "\n",
    "offmask_feats = [\n",
    "    feat for feat in features_valid if feat.masked_word not in train_words\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(47038, 4285)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(onmask_feats), len(offmask_feats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 2\n",
    "ex, feat = examples['valid'][idx], features_valid[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS]      0 1\n",
      "cricket    0 1\n",
      "-          0 1\n",
      "[MASKU]    1 1\n",
      "take       0 1\n",
      "over       0 1\n",
      "at         0 1\n",
      "top        0 1\n",
      "after      0 1\n",
      "innings    0 1\n",
      "victory    0 1\n",
      ".          0 1\n",
      "[SEP]      0 1\n",
      "[PAD]      0 0\n",
      "[PAD]      0 0\n",
      "[PAD]      0 0\n",
      "[PAD]      0 0\n",
      "[PAD]      0 0\n",
      "[PAD]      0 0\n",
      "[PAD]      0 0\n",
      "[PAD]      0 0\n",
      "[PAD]      0 0\n",
      "[PAD]      0 0\n",
      "[PAD]      0 0\n",
      "[PAD]      0 0\n",
      "[PAD]      0 0\n",
      "[PAD]      0 0\n",
      "[PAD]      0 0\n",
      "[PAD]      0 0\n",
      "[PAD]      0 0\n",
      "[PAD]      0 0\n",
      "[PAD]      0 0\n",
      "[PAD]      0 0\n",
      "[PAD]      0 0\n",
      "[PAD]      0 0\n",
      "[PAD]      0 0\n",
      "[PAD]      0 0\n",
      "[PAD]      0 0\n",
      "[PAD]      0 0\n",
      "[PAD]      0 0\n",
      "[PAD]      0 0\n",
      "[PAD]      0 0\n",
      "[PAD]      0 0\n",
      "[PAD]      0 0\n",
      "[PAD]      0 0\n",
      "[PAD]      0 0\n",
      "[PAD]      0 0\n",
      "[PAD]      0 0\n",
      "[PAD]      0 0\n",
      "[PAD]      0 0\n",
      "[PAD]      0 0\n",
      "[PAD]      0 0\n",
      "[PAD]      0 0\n",
      "[PAD]      0 0\n",
      "[PAD]      0 0\n",
      "[PAD]      0 0\n",
      "[PAD]      0 0\n",
      "[PAD]      0 0\n",
      "[PAD]      0 0\n",
      "[PAD]      0 0\n",
      "[PAD]      0 0\n",
      "[PAD]      0 0\n",
      "[PAD]      0 0\n",
      "[PAD]      0 0\n",
      "[PAD]      0 0\n",
      "[PAD]      0 0\n",
      "[PAD]      0 0\n",
      "[PAD]      0 0\n",
      "[PAD]      0 0\n",
      "[PAD]      0 0\n",
      "[PAD]      0 0\n",
      "[PAD]      0 0\n",
      "[PAD]      0 0\n",
      "[PAD]      0 0\n",
      "[PAD]      0 0\n",
      "[PAD]      0 0\n",
      "[PAD]      0 0\n",
      "[PAD]      0 0\n",
      "[PAD]      0 0\n",
      "[PAD]      0 0\n",
      "[PAD]      0 0\n",
      "[PAD]      0 0\n",
      "[PAD]      0 0\n",
      "[PAD]      0 0\n",
      "[PAD]      0 0\n",
      "[PAD]      0 0\n",
      "[PAD]      0 0\n",
      "[PAD]      0 0\n",
      "[PAD]      0 0\n",
      "[PAD]      0 0\n",
      "[PAD]      0 0\n",
      "[PAD]      0 0\n",
      "[PAD]      0 0\n",
      "[PAD]      0 0\n",
      "[PAD]      0 0\n",
      "[PAD]      0 0\n",
      "[PAD]      0 0\n",
      "[PAD]      0 0\n",
      "[PAD]      0 0\n",
      "[PAD]      0 0\n",
      "[PAD]      0 0\n",
      "[PAD]      0 0\n",
      "[PAD]      0 0\n",
      "[PAD]      0 0\n",
      "[PAD]      0 0\n",
      "[PAD]      0 0\n",
      "[PAD]      0 0\n",
      "[PAD]      0 0\n",
      "[PAD]      0 0\n",
      "[PAD]      0 0\n",
      "[PAD]      0 0\n",
      "[PAD]      0 0\n",
      "[PAD]      0 0\n",
      "[PAD]      0 0\n",
      "[PAD]      0 0\n",
      "[PAD]      0 0\n",
      "[PAD]      0 0\n",
      "[PAD]      0 0\n",
      "[PAD]      0 0\n",
      "[PAD]      0 0\n",
      "[PAD]      0 0\n",
      "[PAD]      0 0\n",
      "[PAD]      0 0\n",
      "[PAD]      0 0\n",
      "[PAD]      0 0\n",
      "[PAD]      0 0\n",
      "[PAD]      0 0\n",
      "[PAD]      0 0\n"
     ]
    }
   ],
   "source": [
    "zipped = zip(tokenizer.convert_ids_to_tokens(feat.input_ids), feat.label_mask,\n",
    "            feat.input_mask)\n",
    "for tok, lm, im in zipped:\n",
    "    print(f'{tok:10} {lm} {im}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = CoNLL2003Dataset(features_train)\n",
    "ds_valid = CoNLL2003Dataset(features_valid)\n",
    "ds_offvalid = CoNLL2003Dataset(offmask_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_train = DataLoader(ds_train, batch_size=32, pin_memory=True, shuffle=True,  num_workers=4)\n",
    "dl_valid = DataLoader(ds_valid, batch_size=32, pin_memory=True, shuffle=False, num_workers=4)\n",
    "dl_offvalid = DataLoader(ds_offvalid, batch_size=32, pin_memory=True, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_fn(model, dataloader, return_conf=False):\n",
    "    model.eval()\n",
    "    losses, accuracies = [], []\n",
    "    y_trues, y_preds = [], []\n",
    "    for input_ids, input_mask, label_ids, label_mask in tqdm(dataloader, desc='Evaluating', leave=False):\n",
    "        input_ids, input_mask, label_ids, label_mask = to_device(input_ids, input_mask, label_ids,\n",
    "                                                                 label_mask, device=device)\n",
    "        with torch.no_grad():\n",
    "            loss, active_logits, active_labels = model(\n",
    "                input_ids, input_mask, label_ids, label_mask)\n",
    "            \n",
    "        losses.append(loss.item())\n",
    "        \n",
    "        active_logits = active_logits.argmax(dim=1).cpu().numpy()\n",
    "        active_labels = active_labels.cpu().numpy()\n",
    "        accs = (1 * (active_logits == active_labels)).tolist()\n",
    "        \n",
    "        y_trues += active_labels.tolist()\n",
    "        y_preds += active_logits.tolist()\n",
    "        accuracies += accs\n",
    "        \n",
    "    conf = confusion_matrix([LABELS[y] for y in y_trues], [LABELS[y] for y in y_preds], labels=LABELS)\n",
    "    if return_conf:\n",
    "        return conf\n",
    "    print(conf)\n",
    "        \n",
    "        # transforming\n",
    "#         ts, ps = remap(input_ids, input_mask, label_ids, label_mask, active_logits, active_labels)\n",
    "#         y_preds += ps\n",
    "#         y_trues += ts\n",
    "        \n",
    "#     print(y_preds, y_trues)\n",
    "#     print(classification_report(y_trues, y_preds))\n",
    "            \n",
    "    return np.array(losses).mean(), np.array(accuracies).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bert Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets do this with the X tag for training and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "# device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['O',\n",
       "  'B-MISC',\n",
       "  'I-MISC',\n",
       "  'B-PER',\n",
       "  'I-PER',\n",
       "  'B-ORG',\n",
       "  'I-ORG',\n",
       "  'B-LOC',\n",
       "  'I-LOC'],\n",
       " 9)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LABELS = [\n",
    "    l for l in labels if l not in ['[PAD]', '[CLS]', '[SEP]', 'X']\n",
    "]\n",
    "LABELS, len(LABELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = BertConfig.from_pretrained('../bert-base-cased/', num_labels=len(LABELS), output_hidden_states=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertLSTMForMaskedNerClassification(BertForMaskedNERClassification):\n",
    "    \n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        \n",
    "        del self.classifier, self.dropout\n",
    "        \n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=768,\n",
    "            hidden_size=100,\n",
    "            num_layers=2,\n",
    "            batch_first=True,\n",
    "            dropout=0.1,\n",
    "            bidirectional=True\n",
    "        )\n",
    "        \n",
    "    def forward(self, input_ids, input_mask, label_ids, label_mask):\n",
    "\n",
    "        _, _, hidden_states = self.bert(input_ids, attention_mask=input_mask)\n",
    "\n",
    "        out = self.pooler(hidden_states)\n",
    "\n",
    "        out, _ = self.lstm(out)\n",
    "        # take the active logits\n",
    "        label_mask = label_mask.view(-1)\n",
    "        active_logits = out.view(-1, self.num_labels)[label_mask == 1]\n",
    "\n",
    "        # take the active labels\n",
    "        # remove one because of the [PAD] being the 0 moved to DATASET\n",
    "        active_labels = label_ids.view(-1)[label_mask == 1]\n",
    "\n",
    "        # calc the loss\n",
    "        loss = self.loss_fct(active_logits, active_labels)\n",
    "\n",
    "        return loss, active_logits, active_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BertForMaskedNERClassification(config, weight_O=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForMaskedNERClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=9, bias=True)\n",
       "  (loss_fct): CrossEntropyLoss()\n",
       ")"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=5e-5, weight_decay=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Evaluating', max=1604, style=ProgressStyle(description_width=â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[36241    16   162   650  1764  1413  1619    60   808]\n",
      " [  804    70     2    16     3    22     1     2     2]\n",
      " [  164     0    65     0    23     0    66     0    28]\n",
      " [  906     0     1   789    88    32    17     1     2]\n",
      " [  166     0     0    12  1061     0    34     0    27]\n",
      " [  744     1     0    27     2   543    17     4     3]\n",
      " [  135     0     6     0    36    14   519     0    41]\n",
      " [ 1470     1     1    43    19   103    12   174    14]\n",
      " [   59     0     3     2    14     0    33     0   146]]\n"
     ]
    }
   ],
   "source": [
    "conf = evaluate_fn(model, dl_valid, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4.421811970256108, 0.7717397657970111)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f7cc08bf310>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(6,6))\n",
    "sns.heatmap(conf, annot=True, fmt='d', yticklabels=LABELS, xticklabels=LABELS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    device = device\n",
    "    fp16 = True\n",
    "    num_epochs = 10\n",
    "    ckp_path = 'bertner_masked_2.ckp'\n",
    "    grad_steps = 1\n",
    "    max_grad_norm = 1.\n",
    "    load_state_dict = True\n",
    "    n_iter = 0\n",
    "    best_acc = 0.86\n",
    "    writer = SummaryWriter('nerbert_masked_2')\n",
    "    epoch = 0\n",
    "args = Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n"
     ]
    }
   ],
   "source": [
    "if args.fp16:# and args.n_iter == 0:\n",
    "    model, optimizer = to_fp16(model, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_IncompatibleKeys(missing_keys=['loss_fct.weight'], unexpected_keys=[])\n"
     ]
    }
   ],
   "source": [
    "if args.load_state_dict:\n",
    "    if os.path.exists('bertner_lastlayer.ckp'):\n",
    "        print(model.load_state_dict(torch.load('bertner_lastlayer.ckp'), strict=False))\n",
    "#     if os.path.exists(args.ckp_path.replace('.ckp', '_optimizer.ckp')):\n",
    "#         optimizer.load_state_dict(torch.load(args.ckp_path.replace('.ckp', '_optimizer.ckp'), map_location='cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1924da3b3fbe455eb74ee0566091d5cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epochs', max=10, style=ProgressStyle(description_width='initiâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5c7299b39b542f6ad387a01357e5948",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=6363), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-64-16e4c2595200>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdl_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdl_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevaluate_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Mestrado/ml-masters/mlpack/bert/ner/train.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(args, model, dl_train, dl_valid, optimizer, scheduler, evaluate_fn)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             loss, _, _ = model(input_ids, input_mask,\n\u001b[0;32m---> 23\u001b[0;31m                                label_ids, label_mask)\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad_steps\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlpenv/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Mestrado/ml-masters/mlpack/bert/ner/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, input_mask, label_ids, label_mask)\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpooler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlpenv/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlpenv/lib/python3.7/site-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask)\u001b[0m\n\u001b[1;32m    625\u001b[0m         encoder_outputs = self.encoder(embedding_output,\n\u001b[1;32m    626\u001b[0m                                        \u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 627\u001b[0;31m                                        head_mask=head_mask)\n\u001b[0m\u001b[1;32m    628\u001b[0m         \u001b[0msequence_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m         \u001b[0mpooled_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpooler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlpenv/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlpenv/lib/python3.7/site-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask)\u001b[0m\n\u001b[1;32m    346\u001b[0m                 \u001b[0mall_hidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_hidden_states\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 348\u001b[0;31m             \u001b[0mlayer_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    349\u001b[0m             \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlpenv/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlpenv/lib/python3.7/site-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask)\u001b[0m\n\u001b[1;32m    327\u001b[0m         \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattention_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m         \u001b[0mintermediate_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 329\u001b[0;31m         \u001b[0mlayer_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintermediate_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    330\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlayer_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mattention_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# add attentions if we output them\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlpenv/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlpenv/lib/python3.7/site-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, input_tensor)\u001b[0m\n\u001b[1;32m    312\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLayerNorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlpenv/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlpenv/lib/python3.7/site-packages/torch/nn/modules/normalization.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    150\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m         return F.layer_norm(\n\u001b[0;32m--> 152\u001b[0;31m             input, self.normalized_shape, self.weight, self.bias, self.eps)\n\u001b[0m\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlpenv/lib/python3.7/site-packages/apex/amp/wrap.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m         new_args = utils.casted_args(cast_fn,\n\u001b[1;32m     26\u001b[0m                                      \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                                      kwargs)\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0morig_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnew_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlpenv/lib/python3.7/site-packages/apex/amp/utils.py\u001b[0m in \u001b[0;36mcasted_args\u001b[0;34m(cast_fn, args, kwargs)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_fp_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m             \u001b[0mnew_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0mnew_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlpenv/lib/python3.7/site-packages/apex/amp/utils.py\u001b[0m in \u001b[0;36mmaybe_float\u001b[0;34m(x, name, verbose)\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmaybe_float\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_cuda\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtype_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'FloatTensor'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(args, model, dl_train, dl_valid, optimizer, evaluate_fn=evaluate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:bertenv]",
   "language": "python",
   "name": "conda-env-bertenv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
