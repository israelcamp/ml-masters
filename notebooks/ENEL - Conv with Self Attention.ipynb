{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, auc, roc_auc_score\n",
    "from sklearn.metrics import precision_recall_curve, average_precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlpack.utils import to_device, to_fp16\n",
    "from mlpack.trainer import TrainArgs, BaseTrainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_id = pd.read_csv('../datasets/ENEL/log_norm_clean_data_train.csv', usecols=[0], sep=',')\n",
    "valid_id = pd.read_csv('../datasets/ENEL/log_norm_clean_data_valid.csv', usecols=[0], sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2014-01-01 00:00:00</th>\n",
       "      <th>2014-01-02 00:00:00</th>\n",
       "      <th>2014-01-03 00:00:00</th>\n",
       "      <th>2014-01-04 00:00:00</th>\n",
       "      <th>2014-01-05 00:00:00</th>\n",
       "      <th>2014-01-06 00:00:00</th>\n",
       "      <th>2014-01-07 00:00:00</th>\n",
       "      <th>2014-01-08 00:00:00</th>\n",
       "      <th>2014-01-09 00:00:00</th>\n",
       "      <th>2014-01-10 00:00:00</th>\n",
       "      <th>...</th>\n",
       "      <th>2016-10-23 00:00:00</th>\n",
       "      <th>2016-10-24 00:00:00</th>\n",
       "      <th>2016-10-25 00:00:00</th>\n",
       "      <th>2016-10-26 00:00:00</th>\n",
       "      <th>2016-10-27 00:00:00</th>\n",
       "      <th>2016-10-28 00:00:00</th>\n",
       "      <th>2016-10-29 00:00:00</th>\n",
       "      <th>2016-10-30 00:00:00</th>\n",
       "      <th>2016-10-31 00:00:00</th>\n",
       "      <th>flag</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CONS_NO</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0387DD8A07E07FDA6271170F86AD9151</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.305338</td>\n",
       "      <td>0.306095</td>\n",
       "      <td>0.360579</td>\n",
       "      <td>0.207343</td>\n",
       "      <td>0.331067</td>\n",
       "      <td>0.351877</td>\n",
       "      <td>0.285285</td>\n",
       "      <td>0.346580</td>\n",
       "      <td>0.255016</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>01D6177B5D4FFE0CABA9EF17DAFC2B84</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4B75AC4F2D8434CFF62DB64D0BB43103</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.963074</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>B32AC8CC6D5D805AC053557AB05F5343</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.497605</td>\n",
       "      <td>0.568034</td>\n",
       "      <td>0.490694</td>\n",
       "      <td>0.644715</td>\n",
       "      <td>0.684207</td>\n",
       "      <td>0.590742</td>\n",
       "      <td>0.633854</td>\n",
       "      <td>0.475885</td>\n",
       "      <td>0.385710</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>EDFC78B07BA2908B3395C4EB2304665E</td>\n",
       "      <td>0.106331</td>\n",
       "      <td>0.248451</td>\n",
       "      <td>0.318474</td>\n",
       "      <td>0.128116</td>\n",
       "      <td>0.143158</td>\n",
       "      <td>0.233409</td>\n",
       "      <td>0.201251</td>\n",
       "      <td>0.146789</td>\n",
       "      <td>0.139008</td>\n",
       "      <td>0.133303</td>\n",
       "      <td>...</td>\n",
       "      <td>0.486010</td>\n",
       "      <td>0.395240</td>\n",
       "      <td>0.272830</td>\n",
       "      <td>0.272311</td>\n",
       "      <td>0.304988</td>\n",
       "      <td>0.345965</td>\n",
       "      <td>0.520762</td>\n",
       "      <td>0.467337</td>\n",
       "      <td>0.408207</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 1035 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  2014-01-01 00:00:00  2014-01-02 00:00:00  \\\n",
       "CONS_NO                                                                      \n",
       "0387DD8A07E07FDA6271170F86AD9151             0.000000             0.000000   \n",
       "01D6177B5D4FFE0CABA9EF17DAFC2B84             0.000000             0.000000   \n",
       "4B75AC4F2D8434CFF62DB64D0BB43103             0.000000             0.000000   \n",
       "B32AC8CC6D5D805AC053557AB05F5343             0.000000             0.000000   \n",
       "EDFC78B07BA2908B3395C4EB2304665E             0.106331             0.248451   \n",
       "\n",
       "                                  2014-01-03 00:00:00  2014-01-04 00:00:00  \\\n",
       "CONS_NO                                                                      \n",
       "0387DD8A07E07FDA6271170F86AD9151             0.000000             0.000000   \n",
       "01D6177B5D4FFE0CABA9EF17DAFC2B84             0.000000             0.000000   \n",
       "4B75AC4F2D8434CFF62DB64D0BB43103             0.000000             0.000000   \n",
       "B32AC8CC6D5D805AC053557AB05F5343             0.000000             0.000000   \n",
       "EDFC78B07BA2908B3395C4EB2304665E             0.318474             0.128116   \n",
       "\n",
       "                                  2014-01-05 00:00:00  2014-01-06 00:00:00  \\\n",
       "CONS_NO                                                                      \n",
       "0387DD8A07E07FDA6271170F86AD9151             0.000000             0.000000   \n",
       "01D6177B5D4FFE0CABA9EF17DAFC2B84             0.000000             0.000000   \n",
       "4B75AC4F2D8434CFF62DB64D0BB43103             0.000000             0.000000   \n",
       "B32AC8CC6D5D805AC053557AB05F5343             0.000000             0.000000   \n",
       "EDFC78B07BA2908B3395C4EB2304665E             0.143158             0.233409   \n",
       "\n",
       "                                  2014-01-07 00:00:00  2014-01-08 00:00:00  \\\n",
       "CONS_NO                                                                      \n",
       "0387DD8A07E07FDA6271170F86AD9151             0.000000             0.000000   \n",
       "01D6177B5D4FFE0CABA9EF17DAFC2B84             0.000000             0.000000   \n",
       "4B75AC4F2D8434CFF62DB64D0BB43103             0.000000             0.000000   \n",
       "B32AC8CC6D5D805AC053557AB05F5343             0.000000             0.000000   \n",
       "EDFC78B07BA2908B3395C4EB2304665E             0.201251             0.146789   \n",
       "\n",
       "                                  2014-01-09 00:00:00  2014-01-10 00:00:00  \\\n",
       "CONS_NO                                                                      \n",
       "0387DD8A07E07FDA6271170F86AD9151             0.000000             0.000000   \n",
       "01D6177B5D4FFE0CABA9EF17DAFC2B84             0.000000             0.000000   \n",
       "4B75AC4F2D8434CFF62DB64D0BB43103             0.000000             0.000000   \n",
       "B32AC8CC6D5D805AC053557AB05F5343             0.000000             0.000000   \n",
       "EDFC78B07BA2908B3395C4EB2304665E             0.139008             0.133303   \n",
       "\n",
       "                                  ...  2016-10-23 00:00:00  \\\n",
       "CONS_NO                           ...                        \n",
       "0387DD8A07E07FDA6271170F86AD9151  ...             0.305338   \n",
       "01D6177B5D4FFE0CABA9EF17DAFC2B84  ...             0.000000   \n",
       "4B75AC4F2D8434CFF62DB64D0BB43103  ...             1.000000   \n",
       "B32AC8CC6D5D805AC053557AB05F5343  ...             0.497605   \n",
       "EDFC78B07BA2908B3395C4EB2304665E  ...             0.486010   \n",
       "\n",
       "                                  2016-10-24 00:00:00  2016-10-25 00:00:00  \\\n",
       "CONS_NO                                                                      \n",
       "0387DD8A07E07FDA6271170F86AD9151             0.306095             0.360579   \n",
       "01D6177B5D4FFE0CABA9EF17DAFC2B84             0.000000             0.000000   \n",
       "4B75AC4F2D8434CFF62DB64D0BB43103             1.000000             1.000000   \n",
       "B32AC8CC6D5D805AC053557AB05F5343             0.568034             0.490694   \n",
       "EDFC78B07BA2908B3395C4EB2304665E             0.395240             0.272830   \n",
       "\n",
       "                                  2016-10-26 00:00:00  2016-10-27 00:00:00  \\\n",
       "CONS_NO                                                                      \n",
       "0387DD8A07E07FDA6271170F86AD9151             0.207343             0.331067   \n",
       "01D6177B5D4FFE0CABA9EF17DAFC2B84             0.000000             0.000000   \n",
       "4B75AC4F2D8434CFF62DB64D0BB43103             1.000000             1.000000   \n",
       "B32AC8CC6D5D805AC053557AB05F5343             0.644715             0.684207   \n",
       "EDFC78B07BA2908B3395C4EB2304665E             0.272311             0.304988   \n",
       "\n",
       "                                  2016-10-28 00:00:00  2016-10-29 00:00:00  \\\n",
       "CONS_NO                                                                      \n",
       "0387DD8A07E07FDA6271170F86AD9151             0.351877             0.285285   \n",
       "01D6177B5D4FFE0CABA9EF17DAFC2B84             0.000000             0.000000   \n",
       "4B75AC4F2D8434CFF62DB64D0BB43103             1.000000             1.000000   \n",
       "B32AC8CC6D5D805AC053557AB05F5343             0.590742             0.633854   \n",
       "EDFC78B07BA2908B3395C4EB2304665E             0.345965             0.520762   \n",
       "\n",
       "                                  2016-10-30 00:00:00  2016-10-31 00:00:00  \\\n",
       "CONS_NO                                                                      \n",
       "0387DD8A07E07FDA6271170F86AD9151             0.346580             0.255016   \n",
       "01D6177B5D4FFE0CABA9EF17DAFC2B84             0.000000             0.000000   \n",
       "4B75AC4F2D8434CFF62DB64D0BB43103             1.000000             0.963074   \n",
       "B32AC8CC6D5D805AC053557AB05F5343             0.475885             0.385710   \n",
       "EDFC78B07BA2908B3395C4EB2304665E             0.467337             0.408207   \n",
       "\n",
       "                                  flag  \n",
       "CONS_NO                                 \n",
       "0387DD8A07E07FDA6271170F86AD9151     1  \n",
       "01D6177B5D4FFE0CABA9EF17DAFC2B84     1  \n",
       "4B75AC4F2D8434CFF62DB64D0BB43103     1  \n",
       "B32AC8CC6D5D805AC053557AB05F5343     1  \n",
       "EDFC78B07BA2908B3395C4EB2304665E     1  \n",
       "\n",
       "[5 rows x 1035 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../datasets/ENEL/dataset.csv', sep='\\t', index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ones = data[data[:,-1] == 1]\n",
    "data_zeros = data[data[:,-1] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3615, 38757)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_ones), len(data_zeros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2892"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ones_on_train = round(0.8 * len(data_ones))\n",
    "ones_on_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "middle = round(0.7*len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = np.vstack((data_zeros[:middle - ones_on_train], data_ones[:ones_on_train]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_valid = np.vstack((data_zeros[middle - ones_on_train:], data_ones[ones_on_train:]))\n",
    "# data_valid = data_ones[ones_on_train:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((29660, 1035), (12712, 1035))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.shape, data_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = data_train[:,:-1]\n",
    "y_train = data_train[:,-1]\n",
    "\n",
    "x_valid = data_valid[:,:-1]\n",
    "y_valid = data_valid[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.concatenate(([2*[0] for _ in range(len(x_train))], x_train), axis=1)\n",
    "x_valid = np.concatenate(([2*[0] for _ in range(len(x_valid))], x_valid), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((29660, 1036), (12712, 1036))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, x_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(len(x_train), -1, 7)\n",
    "x_train = np.expand_dims(x_train, 1)\n",
    "\n",
    "x_valid = x_valid.reshape(len(x_valid), -1, 7)\n",
    "x_valid = np.expand_dims(x_valid, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((29660, 1, 148, 7), (12712, 1, 148, 7))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, x_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2892, 723)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_train[y_train == 1]), len(y_valid[y_valid == 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_ones = x_train[y_train == 1]\n",
    "y_train_ones = y_train[y_train == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.vstack((x_train, x_train_ones, x_train_ones, x_train_ones))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.concatenate((y_train, y_train_ones, y_train_ones, y_train_ones))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2892, 1, 148, 7)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_ones.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((38336,), (38336, 1, 148, 7))"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape, x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.transpose(0, 1, 3, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_valid = x_valid.transpose(0, 1, 3, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12712, 38336)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_valid), len(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ENELDataset(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        self.x, self.y = x, y\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        x, y = self.x[idx], self.y[idx]\n",
    "#         if y == 0:\n",
    "#             if random.random() < 0.1:\n",
    "#                 i = random.randint(0, len(x_train_ones)-1)\n",
    "#                 x, y = x_train_ones[i], y_train_ones[i]\n",
    "        \n",
    "        return x.astype(np.float32), y.astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = ENELDataset(x_train, y_train)\n",
    "ds_valid = ENELDataset(x_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_train = DataLoader(ds_train, batch_size=32, shuffle=True, pin_memory=True, num_workers=4)\n",
    "dl_valid = DataLoader(ds_valid, batch_size=32, shuffle=False, pin_memory=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "# device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttention(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_size, out_size):\n",
    "        super().__init__()\n",
    "        self.query = nn.Linear(in_size, out_size)\n",
    "        self.key = nn.Linear(in_size, out_size)\n",
    "        self.value = nn.Linear(in_size, out_size)\n",
    "        \n",
    "        self.d = out_size**(0.5)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        q = self.query(x)\n",
    "        k = self.key(x)\n",
    "        v = self.value(x)\n",
    "        z = torch.softmax((q @ k.permute(0, 1, 3, 2))/self.d, dim=-1) @ v\n",
    "        return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttentionConv(nn.Module):\n",
    "    \n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.query = nn.Conv2d(*args, **kwargs)\n",
    "        self.key = nn.Conv2d(*args, **kwargs)\n",
    "        self.value = nn.Conv2d(*args, **kwargs)\n",
    "        \n",
    "        self.d = self.query.out_channels**(0.5)\n",
    "        \n",
    "    def forward(self, *args, **kwargs):\n",
    "        query = self.query(*args, **kwargs)\n",
    "        key = self.key(*args, **kwargs)\n",
    "        value = self.value(*args, **kwargs)\n",
    "        \n",
    "        attention = torch.matmul(query, key.transpose(-2, -1))\n",
    "        attention = attention / self.d\n",
    "        attention = nn.Softmax(dim=-1)(attention)\n",
    "        attention = torch.matmul(attention, value)\n",
    "        return attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvModel(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        dropout = 0.1\n",
    "\n",
    "        self.net = nn.Sequential(            \n",
    "            self.block(148, 256, 1, 90, dropout),\n",
    "            self.block(256, 256, 90, 90, dropout),\n",
    "            self.block(256, 256, 90, 90, dropout),\n",
    "            nn.MaxPool2d(3),\n",
    "        )\n",
    "        self.classifier = nn.Linear(90 * 2 * 85, 2)\n",
    "\n",
    "    def block(self, in_features, out_features, in_channels, out_channels, dropout):\n",
    "        return nn.Sequential(\n",
    "            SelfAttention(in_features, out_features),  # n x in_channels x m x out_features\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),  # n x out_channels x m x out_features\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        o = self.net(x)\n",
    "        o = o.view(x.shape[0], -1)\n",
    "        o = self.classifier(o) \n",
    "        return o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MySelfConvModel(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            self.block(1, 90),\n",
    "            self.block(90, 90),\n",
    "            self.block(90,90),\n",
    "            nn.MaxPool2d(3)\n",
    "        )\n",
    "        self.classifier = nn.Linear(90 * 2 * 49, 2)\n",
    "        \n",
    "    def block(self, in_channels, out_channels, dropout=0.1):\n",
    "        return nn.Sequential(\n",
    "            SelfAttentionConv(in_channels, out_channels, kernel_size=3, padding=1),  # n x out_channels x m x out_features\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        o = self.net(x)\n",
    "        o = o.view(x.shape[0], -1)\n",
    "        o = self.classifier(o)\n",
    "        return o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MySelfConvModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MySelfConvModel(\n",
       "  (net): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): SelfAttentionConv(\n",
       "        (query): Conv2d(1, 90, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (key): Conv2d(1, 90, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (value): Conv2d(1, 90, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): SelfAttentionConv(\n",
       "        (query): Conv2d(90, 90, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (key): Conv2d(90, 90, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (value): Conv2d(90, 90, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): SelfAttentionConv(\n",
       "        (query): Conv2d(90, 90, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (key): Conv2d(90, 90, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (value): Conv2d(90, 90, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (classifier): Linear(in_features=8820, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(iter(dl_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 2])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    o = model(x.to(device))\n",
    "o.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def precision_at_k(y_true,class_probs,k,threshold=0.5,class_of_interest=1,isSorted=False):\n",
    "\n",
    "    if (not isSorted):\n",
    "\n",
    "        # Selecting the probs on the class of interest (coi)\n",
    "        coi_probs = class_probs[:,class_of_interest]\n",
    "\n",
    "        # print('Selecionando as probs da classe de interesse:',class_of_interest)\n",
    "        # print(coi_probs)\n",
    "\n",
    "        # print('Ordem de entrada dos targets')\n",
    "        # print(y_true)\n",
    "\n",
    "        # Sorting the coi probs and selecting the top k\n",
    "        # print('Ordenando as probs e os targets correspondentes:')\n",
    "        sorted_coi_probs = np.sort(coi_probs)[::-1]\n",
    "        sorted_y = y_true[np.argsort(coi_probs)[::-1]]\n",
    "        \n",
    "        # Calculating the precision for \n",
    "        # print(sorted_coi_probs)\n",
    "        # print(sorted_y)\n",
    "\n",
    "    else:\n",
    "        # Code otimization so the algorithm doesn't have to sort the data twice\n",
    "        sorted_coi_probs = class_probs\n",
    "        sorted_y = y_true\n",
    "\n",
    "\n",
    "    # Selecting the top k probs and their respective labels\n",
    "    sorted_coi_probs = sorted_coi_probs[:k]\n",
    "    sorted_y = sorted_y[:k]\n",
    "\n",
    "    # print('Selecionando as top',k,'probs')\n",
    "    # print(sorted_coi_probs)\n",
    "    # print(sorted_y)\n",
    "\n",
    "    # Atributing class based on the threshold\n",
    "    sorted_predicted_classes = np.where(sorted_coi_probs>threshold,\n",
    "                                        float(class_of_interest),\n",
    "                                        0.0)\n",
    "\n",
    "    # print('Atribuindo a classe baseada no threshold de ',threshold)\n",
    "#     print(sorted_predicted_classes)\n",
    "\n",
    "    # print('PrecisÃ£o em K:')\n",
    "\n",
    "    # print(k)\n",
    "\n",
    "    precisionK = np.sum(sorted_predicted_classes == sorted_y)/k  \n",
    "\n",
    "    return precisionK\n",
    "\n",
    "def map_at_N(y_true,class_probs,N,thrs=0.5,class_of_interest=1):\n",
    "\n",
    "    # Calls the precision at k function with the values already sorted and calculates the average precision\n",
    "    # weighted by the number of positive classes inside the sample\n",
    "\n",
    "    # Declaring the list to hold the precisions\n",
    "    pks = []\n",
    "\n",
    "    # Selecting the probs on the class of interest (coi)\n",
    "    coi_probs = class_probs[:,class_of_interest]\n",
    "\n",
    "    # Sorting the class of interest and its respective label\n",
    "    sorted_coi_probs = np.sort(coi_probs)[::-1]\n",
    "    sorted_y = y_true[np.argsort(coi_probs)[::-1]]\n",
    "\n",
    "    # Selecting the top N scores \n",
    "    sorted_coi_probs = sorted_coi_probs[:N]\n",
    "    sorted_y = sorted_y[:N]\n",
    "\n",
    "\n",
    "    ## TESTANDO APENAS ##\n",
    "    sorted_y[-1] = 1 \n",
    "\n",
    "    # Identifying the positions of the class of interest inside the top N\n",
    "    top_coi_indexes = np.argwhere(sorted_y>0)\n",
    "\n",
    "    for value in top_coi_indexes:\n",
    "        \n",
    "        # Adjusting the index\n",
    "        limite = value[0] + 1\n",
    "        \n",
    "        pks.append(\n",
    "                    precision_at_k(sorted_y[:limite],\n",
    "                    sorted_coi_probs[:limite],\n",
    "                    limite,threshold=thrs,isSorted=True)\n",
    "                    )\n",
    "\n",
    "    pks = np.array(pks)\n",
    "    \n",
    "    # print(pks)\n",
    "    # print(sorted_coi_probs)\n",
    "    # print(sorted_y)\n",
    "    return pks.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyTrainer(BaseTrainer):\n",
    "    \n",
    "    @staticmethod\n",
    "    def dataloader_generator(dataloader):\n",
    "        for x, y in dataloader:\n",
    "#             x = x.unsqueeze(-1)\n",
    "            x, y = to_device(x, y, device=device)\n",
    "            yield {\n",
    "                'inputs': {\n",
    "                    'x': x\n",
    "                },\n",
    "                'targets': {\n",
    "                    'y': y\n",
    "                }\n",
    "            }\n",
    "        \n",
    "    @staticmethod\n",
    "    def loss_from_model(model_output, targets, loss_fn=None):\n",
    "        y = targets['y']\n",
    "        return loss_fn(model_output, y)\n",
    "    \n",
    "    def evaluate_fn(self, model, dataloader, loss_fn):\n",
    "        model.eval()\n",
    "        losses = []\n",
    "        preds = []\n",
    "        trues = []\n",
    "        probs = []\n",
    "        dl_gen = self.dataloader_generator(dataloader)\n",
    "        for batch in self.tqdm(dl_gen, leave=False, desc='Eval...', total=len(dataloader)):\n",
    "            inputs = batch['inputs']\n",
    "            targets = batch['targets']\n",
    "\n",
    "            with torch.no_grad():\n",
    "                o = model(**inputs)\n",
    "\n",
    "            loss = self.loss_from_model(o, targets, loss_fn)\n",
    "\n",
    "            y = targets['y']\n",
    "            \n",
    "            probs += torch.softmax(o, dim=-1).detach().cpu().numpy().tolist()\n",
    "            preds += o.argmax(1).detach().cpu().numpy().tolist()\n",
    "            trues += y.detach().cpu().numpy().tolist()\n",
    "            losses.append(loss.item())\n",
    "\n",
    "        acc = accuracy_score(trues, preds)\n",
    "        f1 = f1_score(trues, preds)\n",
    "        conf = confusion_matrix(trues, preds)\n",
    "        map100 = map_at_N(np.array(trues), np.array(probs), 100)\n",
    "#         return trues, preds, probs\n",
    "        roc = roc_auc_score(np.array(trues), np.array(probs)[:,1])\n",
    "\n",
    "        both = sorted([\n",
    "            (x, y) for x, y in zip(preds, trues)\n",
    "        ], key=lambda x:x[0], reverse=True)\n",
    "\n",
    "        p = [x for x,_ in both]\n",
    "        t = [x for _,x in both]\n",
    "\n",
    "        print('--- Validation ---')\n",
    "        print(f'F1 = {f1}\\t Acc = {acc}')\n",
    "        print(f'AUC = {auc(p, t)}')\n",
    "        print(f'MAP@100 = {map100}')\n",
    "        print(f'ROC = {roc}')\n",
    "        print(conf)\n",
    "        return np.array(losses).mean(), map100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss(torch.tensor([1., 1.]).to(device))\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-3, weight_decay=2e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = TrainArgs(40, 'enel_selfatt_conv_3.ckp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = MyTrainer(grad_steps=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_state_dict(torch.load('enel_selfatt_conv.ckp'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# trainer.evaluate_fn(model, dl_valid, loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2054e79052bb44559342516ab1edcdc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Training...', max=40, style=ProgressStyle(description_width='â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1198), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Train Loss 0.5194579885653741\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Eval...', max=398, style=ProgressStyle(description_width='iniâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Validation ---\n",
      "F1 = 0.2768622280817403\t Acc = 0.9137035871617369\n",
      "AUC = 0.5\n",
      "MAP@100 = 0.6080468640760156\n",
      "ROC = 0.7395675173427186\n",
      "[[11405   584]\n",
      " [  513   210]]\n",
      "---Valid\n",
      "Loss 0.29874780856484745\n",
      "Metric 0.6080468640760156\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85e957e66f9741c5a2fce0b5878bf3aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1198), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-71-f8160df15416>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdl_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdl_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/Mestrado/MLMaster/mlpack/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, args, model, dl_train, dl_valid, optimizer, loss_fn, scheduler)\u001b[0m\n\u001b[1;32m    115\u001b[0m                     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m                     torch.nn.utils.clip_grad_norm_(\n\u001b[0;32m--> 117\u001b[0;31m                         model.parameters(), self.max_grad_norm)\n\u001b[0m\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad_steps\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdl_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/bertenv/lib/python3.7/site-packages/torch/nn/utils/clip_grad.py\u001b[0m in \u001b[0;36mclip_grad_norm_\u001b[0;34m(parameters, max_norm, norm_type)\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0mparam_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m             \u001b[0mtotal_norm\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mparam_norm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0mtotal_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtotal_norm\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1.\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mclip_coef\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax_norm\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtotal_norm\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1e-6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.train(args, model, dl_train, dl_valid, optimizer, loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:bertenv]",
   "language": "python",
   "name": "conda-env-bertenv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
